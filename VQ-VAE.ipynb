{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a37b285f-a1f7-4995-ae20-858b052df71c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Using cached numpy-1.26.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.2 MB)\n",
      "Collecting lmdb\n",
      "  Using cached lmdb-1.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (298 kB)\n",
      "Collecting Pillow\n",
      "  Using cached pillow-10.3.0-cp39-cp39-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: PyYAML in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (6.0.1)\n",
      "Collecting pygame\n",
      "  Using cached pygame-2.5.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "Collecting scikit-image\n",
      "  Using cached scikit_image-0.22.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.7 MB)\n",
      "Collecting einops\n",
      "  Using cached einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.9.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "Requirement already satisfied: packaging>=21 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from scikit-image) (24.0)\n",
      "Collecting networkx>=2.8\n",
      "  Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "Collecting tifffile>=2022.8.12\n",
      "  Using cached tifffile-2024.5.22-py3-none-any.whl (225 kB)\n",
      "Collecting lazy_loader>=0.3\n",
      "  Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Collecting imageio>=2.27\n",
      "  Using cached imageio-2.34.1-py3-none-any.whl (313 kB)\n",
      "Collecting pandas>=1.2\n",
      "  Using cached pandas-2.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (304 kB)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Using cached pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (2.9.0)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.52.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Using cached kiwisolver-1.4.5-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (6.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.17.0)\n",
      "Collecting tzdata>=2022.7\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Installing collected packages: numpy, tzdata, pyparsing, Pillow, kiwisolver, fonttools, cycler, contourpy, tifffile, scipy, pandas, networkx, matplotlib, lazy-loader, imageio, tqdm, seaborn, scikit-image, pygame, opencv-python, lmdb, einops\n",
      "Successfully installed Pillow-10.3.0 contourpy-1.2.1 cycler-0.12.1 einops-0.8.0 fonttools-4.52.4 imageio-2.34.1 kiwisolver-1.4.5 lazy-loader-0.4 lmdb-1.4.1 matplotlib-3.9.0 networkx-3.2.1 numpy-1.26.4 opencv-python-4.9.0.80 pandas-2.2.2 pygame-2.5.2 pyparsing-3.1.2 scikit-image-0.22.0 scipy-1.13.1 seaborn-0.13.2 tifffile-2024.5.22 tqdm-4.66.4 tzdata-2024.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy opencv-python lmdb Pillow tqdm PyYAML pygame scipy scikit-image einops seaborn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a115c5fe-870b-4a72-930e-abf845eb5849",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting apex\n",
      "  Using cached apex-0.9.10.dev0-py3-none-any.whl\n",
      "Collecting sconf\n",
      "  Using cached sconf-0.2.5-py3-none-any.whl (8.8 kB)\n",
      "Collecting pyramid-mailer\n",
      "  Using cached pyramid_mailer-0.15.1-py2.py3-none-any.whl (19 kB)\n",
      "Collecting pyramid>1.1.2\n",
      "  Using cached pyramid-2.0.2-py3-none-any.whl (247 kB)\n",
      "Collecting wtforms-recaptcha\n",
      "  Using cached wtforms_recaptcha-0.3.2-py2.py3-none-any.whl (7.5 kB)\n",
      "Collecting wtforms\n",
      "  Using cached wtforms-3.1.2-py3-none-any.whl (145 kB)\n",
      "Collecting zope.sqlalchemy\n",
      "  Using cached zope.sqlalchemy-3.1-py3-none-any.whl (23 kB)\n",
      "Collecting cryptacular\n",
      "  Using cached cryptacular-1.6.2-cp39-cp39-linux_x86_64.whl\n",
      "Collecting velruse>=1.0.3\n",
      "  Using cached velruse-1.1.1-py3-none-any.whl\n",
      "Requirement already satisfied: requests in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from apex) (2.31.0)\n",
      "Collecting ruamel.yaml\n",
      "  Downloading ruamel.yaml-0.18.6-py3-none-any.whl (117 kB)\n",
      "\u001b[K     |████████████████████████████████| 117 kB 5.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting munch\n",
      "  Using cached munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
      "Collecting plaster\n",
      "  Using cached plaster-1.1.2-py2.py3-none-any.whl (11 kB)\n",
      "Collecting plaster-pastedeploy\n",
      "  Using cached plaster_pastedeploy-1.0.1-py2.py3-none-any.whl (7.8 kB)\n",
      "Collecting hupper>=1.5\n",
      "  Using cached hupper-1.12.1-py3-none-any.whl (22 kB)\n",
      "Collecting zope.deprecation>=3.5.0\n",
      "  Using cached zope.deprecation-5.0-py3-none-any.whl (10 kB)\n",
      "Collecting webob>=1.8.3\n",
      "  Using cached WebOb-1.8.7-py2.py3-none-any.whl (114 kB)\n",
      "Requirement already satisfied: setuptools in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pyramid>1.1.2->apex) (69.5.1)\n",
      "Collecting venusian>=1.0\n",
      "  Using cached venusian-3.1.0-py3-none-any.whl (13 kB)\n",
      "Collecting translationstring>=0.4\n",
      "  Using cached translationstring-1.4-py2.py3-none-any.whl (15 kB)\n",
      "Collecting zope.interface>=3.8.0\n",
      "  Using cached zope.interface-6.4.post2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (246 kB)\n",
      "Collecting python3-openid\n",
      "  Using cached python3_openid-3.2.0-py3-none-any.whl (133 kB)\n",
      "Collecting anykeystore\n",
      "  Using cached anykeystore-0.2-py3-none-any.whl\n",
      "Collecting requests-oauthlib\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting pbkdf2\n",
      "  Using cached pbkdf2-1.3-py3-none-any.whl\n",
      "Collecting PasteDeploy>=2.0\n",
      "  Using cached PasteDeploy-3.1.0-py3-none-any.whl (16 kB)\n",
      "Collecting transaction\n",
      "  Using cached transaction-4.0-py3-none-any.whl (46 kB)\n",
      "Collecting repoze.sendmail>=4.1\n",
      "  Using cached repoze.sendmail-4.4.1-py2.py3-none-any.whl (41 kB)\n",
      "Requirement already satisfied: defusedxml in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from python3-openid->velruse>=1.0.3->apex) (0.7.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->apex) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->apex) (2024.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->apex) (3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->apex) (3.3.2)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Collecting ruamel.yaml.clib>=0.2.7\n",
      "  Downloading ruamel.yaml.clib-0.2.8-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (562 kB)\n",
      "\u001b[K     |████████████████████████████████| 562 kB 58.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: markupsafe in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from wtforms->apex) (2.1.5)\n",
      "Collecting SQLAlchemy!=1.4.0,!=1.4.1,!=1.4.2,!=1.4.3,!=1.4.4,!=1.4.5,!=1.4.6,>=1.1\n",
      "  Downloading SQLAlchemy-2.0.30-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1 MB 102.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from zope.sqlalchemy->apex) (24.0)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Downloading greenlet-3.0.3-cp39-cp39-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (614 kB)\n",
      "\u001b[K     |████████████████████████████████| 614 kB 71.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.6.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from SQLAlchemy!=1.4.0,!=1.4.1,!=1.4.2,!=1.4.3,!=1.4.4,!=1.4.5,!=1.4.6,>=1.1->zope.sqlalchemy->apex) (4.11.0)\n",
      "Installing collected packages: zope.interface, plaster, PasteDeploy, zope.deprecation, webob, venusian, translationstring, transaction, plaster-pastedeploy, oauthlib, hupper, greenlet, wtforms, SQLAlchemy, ruamel.yaml.clib, requests-oauthlib, repoze.sendmail, python3-openid, pyramid, pbkdf2, anykeystore, zope.sqlalchemy, wtforms-recaptcha, velruse, ruamel.yaml, pyramid-mailer, munch, cryptacular, sconf, apex\n",
      "Successfully installed PasteDeploy-3.1.0 SQLAlchemy-2.0.30 anykeystore-0.2 apex-0.9.10.dev0 cryptacular-1.6.2 greenlet-3.0.3 hupper-1.12.1 munch-4.0.0 oauthlib-3.2.2 pbkdf2-1.3 plaster-1.1.2 plaster-pastedeploy-1.0.1 pyramid-2.0.2 pyramid-mailer-0.15.1 python3-openid-3.2.0 repoze.sendmail-4.4.1 requests-oauthlib-2.0.0 ruamel.yaml-0.18.6 ruamel.yaml.clib-0.2.8 sconf-0.2.5 transaction-4.0 translationstring-1.4 velruse-1.1.1 venusian-3.1.0 webob-1.8.7 wtforms-3.1.2 wtforms-recaptcha-0.3.2 zope.deprecation-5.0 zope.interface-6.4.post2 zope.sqlalchemy-3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install apex sconf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e42ae1f5-3eb1-41ed-a1c5-f56fd98c523d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torch-2.3.0%2Bcu118-cp39-cp39-linux_x86_64.whl (839.7 MB)\n",
      "\u001b[K     |████████████▎                   | 322.4 MB 137.7 MB/s eta 0:00:04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |███████████████████████▌        | 617.1 MB 136.8 MB/s eta 0:00:02"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |█████████████████████████████▎  | 767.5 MB 129.7 MB/s eta 0:00:01"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 839.7 MB 8.2 kB/s \n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.18.0%2Bcu118-cp39-cp39-linux_x86_64.whl (6.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.3 MB 122.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.3.0%2Bcu118-cp39-cp39-linux_x86_64.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 66.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-nccl-cu11==2.20.5\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.20.5-py3-none-manylinux2014_x86_64.whl (142.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 142.9 MB 111.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.1 MB 48.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sympy\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.7 MB 90.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.8.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (4.11.0)\n",
      "Collecting nvidia-cusolver-cu11==11.4.1.48\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 128.2 MB 144.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
      "\u001b[K     |████████████████████████████████| 875 kB 96.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting triton==2.3.0\n",
      "  Downloading https://download.pytorch.org/whl/triton-2.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 168.1 MB 32 kB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.8.89\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 23.2 MB 95.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.7.0.84\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-8.7.0.84-py3-none-manylinux1_x86_64.whl (728.5 MB)\n",
      "\u001b[K     |██████████████                  | 318.9 MB 108.0 MB/s eta 0:00:04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████▌   | 648.7 MB 113.6 MB/s eta 0:00:01"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 728.5 MB 3.7 kB/s \n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (3.1.3)\n",
      "Collecting fsspec\n",
      "  Downloading https://download.pytorch.org/whl/fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "\u001b[K     |████████████████████████████████| 170 kB 116.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: networkx in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Collecting filelock\n",
      "  Downloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Collecting nvidia-curand-cu11==10.3.0.86\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 58.1 MB 105.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 204.1 MB 20 kB/s /s eta 0:00:01  |█                               | 6.0 MB 64.2 MB/s eta 0:00:04\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
      "\u001b[K     |██████████████████████▏         | 289.7 MB 128.9 MB/s eta 0:00:01"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 417.9 MB 22 kB/s /s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 168.4 MB 112 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[K     |████████████████████████████████| 99 kB 19.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from jinja2->torch) (2.1.5)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[K     |████████████████████████████████| 536 kB 77.4 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: nvidia-cublas-cu11, mpmath, filelock, triton, sympy, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-cusolver-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cudnn-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, fsspec, torch, torchvision, torchaudio\n",
      "Successfully installed filelock-3.13.1 fsspec-2024.2.0 mpmath-1.3.0 nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-8.7.0.84 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.20.5 nvidia-nvtx-cu11-11.8.86 sympy-1.12 torch-2.3.0+cu118 torchaudio-2.3.0+cu118 torchvision-0.18.0+cu118 triton-2.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e12cff5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/dell/pycharm_remote/VQ-Font/\") # the absolute path to the code\n",
    "import numpy as np\n",
    "from scipy.signal import savgol_filter\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from six.moves import xrange\n",
    "import os\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from model import content_enc_builder\n",
    "from model import dec_builder\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image, ImageFile\n",
    "from model.modules import weights_init\n",
    "import pprint\n",
    "import json\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f867e7a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VectorQuantizer(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, commitment_cost):\n",
    "        super(VectorQuantizer, self).__init__()\n",
    "\n",
    "        self._num_embeddings = num_embeddings\n",
    "        self._embedding_dim = embedding_dim\n",
    "        self._commitment_cost = commitment_cost\n",
    "\n",
    "        self._embedding = nn.Embedding(self._num_embeddings, self._embedding_dim)\n",
    "        self._embedding.weight.data.uniform_(-1 / self._num_embeddings, 1 / self._num_embeddings)\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # 传入的是图片经过encoder后的feature maps\n",
    "        # convert inputs from BCHW\n",
    "        input_shape = inputs.shape\n",
    "\n",
    "        # Flatten input ->[BC HW]\n",
    "        flat_input = inputs.view(-1, self._embedding_dim)\n",
    "\n",
    "        # Calculate distances\n",
    "        distances = (torch.sum(flat_input ** 2, dim=1, keepdim=True)\n",
    "                     + torch.sum(self._embedding.weight ** 2, dim=1)\n",
    "                     - 2 * torch.matmul(flat_input, self._embedding.weight.t()))\n",
    "\n",
    "        # Encoding\n",
    "        encoding_indices = torch.argmin(distances, dim=1).unsqueeze(1) #得到编号\n",
    "        encodings = torch.zeros(encoding_indices.shape[0], self._num_embeddings, device=inputs.device)\n",
    "        encodings.scatter_(1, encoding_indices, 1)\n",
    "\n",
    "        # Quantize and unflatten\n",
    "        quantized = torch.matmul(encodings, self._embedding.weight).view(input_shape)\n",
    "\n",
    "        # Loss\n",
    "        e_latent_loss = F.mse_loss(quantized.detach(), inputs)\n",
    "        q_latent_loss = F.mse_loss(quantized, inputs.detach())\n",
    "        loss = q_latent_loss + self._commitment_cost * e_latent_loss\n",
    "\n",
    "        quantized = inputs + (quantized - inputs).detach()\n",
    "        avg_probs = torch.mean(encodings, dim=0)\n",
    "        perplexity = torch.exp(-torch.sum(avg_probs * torch.log(avg_probs + 1e-10)))\n",
    "\n",
    "        # convert quantized from BHWC -> BCHW\n",
    "        return loss, quantized, perplexity, encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc442a34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VectorQuantizerEMA(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, commitment_cost, decay, epsilon=1e-5):\n",
    "        super(VectorQuantizerEMA, self).__init__()\n",
    "\n",
    "        self._embedding_dim = embedding_dim\n",
    "        self._num_embeddings = num_embeddings\n",
    "\n",
    "        self._embedding = nn.Embedding(self._num_embeddings, self._embedding_dim)\n",
    "        self._embedding.weight.data.normal_()\n",
    "        self._commitment_cost = commitment_cost\n",
    "\n",
    "        self.register_buffer('_ema_cluster_size', torch.zeros(num_embeddings))\n",
    "        self._ema_w = nn.Parameter(torch.Tensor(num_embeddings, self._embedding_dim))\n",
    "        self._ema_w.data.normal_()\n",
    "\n",
    "        self._decay = decay\n",
    "        self._epsilon = epsilon\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # convert inputs from BCHW -> BHWC\n",
    "        inputs = inputs.permute(0, 2, 3, 1).contiguous()\n",
    "        input_shape = inputs.shape\n",
    "\n",
    "        # Flatten input\n",
    "        flat_input = inputs.view(-1, self._embedding_dim)\n",
    "\n",
    "        # Calculate distances\n",
    "        distances = (torch.sum(flat_input ** 2, dim=1, keepdim=True)\n",
    "                     + torch.sum(self._embedding.weight ** 2, dim=1)\n",
    "                     - 2 * torch.matmul(flat_input, self._embedding.weight.t()))\n",
    "\n",
    "        # Encoding\n",
    "        encoding_indices = torch.argmin(distances, dim=1).unsqueeze(1)\n",
    "        encodings = torch.zeros(encoding_indices.shape[0], self._num_embeddings, device=inputs.device)\n",
    "        encodings.scatter_(1, encoding_indices, 1)\n",
    "\n",
    "        # Quantize and unflatten\n",
    "        quantized = torch.matmul(encodings, self._embedding.weight).view(input_shape)\n",
    "\n",
    "        # Use EMA to update the embedding vectors\n",
    "        if self.training:\n",
    "            self._ema_cluster_size = self._ema_cluster_size * self._decay + \\\n",
    "                                     (1 - self._decay) * torch.sum(encodings, 0)\n",
    "\n",
    "            # Laplace smoothing of the cluster size\n",
    "            n = torch.sum(self._ema_cluster_size.data)\n",
    "            self._ema_cluster_size = (\n",
    "                    (self._ema_cluster_size + self._epsilon)\n",
    "                    / (n + self._num_embeddings * self._epsilon) * n)\n",
    "\n",
    "            dw = torch.matmul(encodings.t(), flat_input)\n",
    "            self._ema_w = nn.Parameter(self._ema_w * self._decay + (1 - self._decay) * dw)\n",
    "\n",
    "            self._embedding.weight = nn.Parameter(self._ema_w / self._ema_cluster_size.unsqueeze(1))\n",
    "\n",
    "        # Loss\n",
    "        e_latent_loss = F.mse_loss(quantized.detach(), inputs)\n",
    "        loss = self._commitment_cost * e_latent_loss\n",
    "\n",
    "        # Straight Through Estimator\n",
    "        quantized = inputs + (quantized - inputs).detach()\n",
    "        avg_probs = torch.mean(encodings, dim=0)\n",
    "        perplexity = torch.exp(-torch.sum(avg_probs * torch.log(avg_probs + 1e-10)))\n",
    "\n",
    "        # convert quantized from BHWC -> BCHW\n",
    "        return loss, quantized.permute(0, 3, 1, 2).contiguous(), perplexity, encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdd437fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, commitment_cost, decay=0):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self._encoder = content_enc_builder(1,32,256)\n",
    "\n",
    "        if decay > 0.0:\n",
    "            self._vq_vae = VectorQuantizerEMA(num_embeddings, embedding_dim,\n",
    "                                              commitment_cost, decay)\n",
    "        else:\n",
    "            self._vq_vae = VectorQuantizer(num_embeddings, embedding_dim,\n",
    "                                           commitment_cost)\n",
    "        self._decoder = dec_builder(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self._encoder(x) #[B 256 16 16]\n",
    "        loss, quantized, perplexity, _ = self._vq_vae(z)\n",
    "        x_recon = self._decoder(quantized)\n",
    "\n",
    "        return loss, x_recon, perplexity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59573f1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CombTrain_VQ_VAE_dataset(Dataset):\n",
    "    \"\"\"\n",
    "    CombTrain_VQ_VAE_dataset, learn the laten codebook from content font. \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root, transform = None):\n",
    "        self.img_path = root\n",
    "        self.transform = transform\n",
    "        self.imgs = self.read_file(self.img_path)\n",
    "        # img = Image.open(self.imgs[0])\n",
    "        # img = self.transform(img)\n",
    "        # print(img.shape)\n",
    "\n",
    "\n",
    "    def read_file(self, path):\n",
    "        \"\"\"从文件夹中读取数据\"\"\"\n",
    "        files_list = os.listdir(path)\n",
    "        file_path_list = [os.path.join(path, img) for img in files_list]\n",
    "        file_path_list.sort()\n",
    "        return file_path_list\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name = self.imgs[index]\n",
    "        #print(img_name[-5:-4])\n",
    "        img = Image.open(img_name)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img) #Tensor [C H W] [1 128 128]\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4b99062",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 iterations\n",
      "recon_error: 0.474\n",
      "perplexity: 7.344\n",
      "vq_loss: 701.347\n",
      "\n",
      "2000 iterations\n",
      "recon_error: 0.284\n",
      "perplexity: 9.450\n",
      "vq_loss: 12.611\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 59\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# print(train_data_variance)\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# show(make_grid(data.cpu().data) )\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# break\u001b[39;00m\n\u001b[0;32m     58\u001b[0m data \u001b[38;5;241m=\u001b[39m data \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;66;03m# normalize to [-0.5, 0.5]\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     62\u001b[0m vq_loss, data_recon, perplexity \u001b[38;5;241m=\u001b[39m model(data)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torchvision.utils import make_grid\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_imgs_path = 'data/content/arial_115'\n",
    "tensorize_transform = transforms.Compose([transforms.Resize((128, 128)),\n",
    "                                          transforms.ToTensor()])\n",
    "\n",
    "train_dataset = CombTrain_VQ_VAE_dataset(train_imgs_path, transform=tensorize_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=5, batch_sampler=None, drop_last=True, pin_memory=True, shuffle=True)\n",
    "\n",
    "num_training_updates = 200000\n",
    "\n",
    "embedding_dim = 256\n",
    "num_embeddings = 100\n",
    "\n",
    "commitment_cost = 0.25\n",
    "\n",
    "decay = 0\n",
    "\n",
    "learning_rate = 2e-4\n",
    "\n",
    "model = Model(num_embeddings, embedding_dim, commitment_cost, decay).to(device)\n",
    "model.apply(weights_init(\"xavier\"))\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, amsgrad=False)\n",
    "\n",
    "model.train()\n",
    "train_res_recon_error = []\n",
    "train_res_perplexity = []\n",
    "train_vq_loss = []\n",
    "\n",
    "\n",
    "def val(model,validation_loader):\n",
    "    model.eval()\n",
    "\n",
    "    valid_originals = next(iter(validation_loader))\n",
    "    valid_originals = valid_originals.to(device)\n",
    "\n",
    "    vq_output_eval = model._encoder(valid_originals)\n",
    "    _, valid_quantize, _, _ = model._vq_vae(vq_output_eval)\n",
    "    valid_reconstructions = model._decoder(valid_quantize)\n",
    "\n",
    "def show(img):\n",
    "    npimg = img.numpy()\n",
    "    fig = plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
    "    fig.axes.get_xaxis().set_visible(False)\n",
    "    fig.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "\n",
    "for i in xrange(num_training_updates):\n",
    "    data = next(iter(train_loader))\n",
    "    train_data_variance = torch.var(data)\n",
    "    # print(train_data_variance)\n",
    "    # show(make_grid(data.cpu().data) )\n",
    "    # break\n",
    "    data = data - 0.5 # normalize to [-0.5, 0.5]\n",
    "    data = data.to(device)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    vq_loss, data_recon, perplexity = model(data)\n",
    "    # data_recon重构图像\n",
    "    # print(\"vq_loss\\n\",vq_loss)\n",
    "    recon_error = F.mse_loss(data_recon, data) / train_data_variance\n",
    "    loss = recon_error + vq_loss\n",
    "    # 重构损失更新encoder以及decoder,vq_loss用来更新embedding空间\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    train_res_recon_error.append(recon_error.item())\n",
    "    train_res_perplexity.append(perplexity.item())\n",
    "    train_vq_loss.append(vq_loss.item())\n",
    "\n",
    "    if (i + 1) % 1000 == 0:\n",
    "        print('%d iterations' % (i + 1))\n",
    "        print('recon_error: %.3f' % np.mean(train_res_recon_error[-1000:]))\n",
    "        print('perplexity: %.3f' % np.mean(train_res_perplexity[-1000:]))\n",
    "        print('vq_loss: %.3f' % np.mean(train_vq_loss[-1000:]))\n",
    "        print()\n",
    "        # show(make_grid(data.cpu().data) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf4ba5cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_imgs_path = 'data/content/arial_21'\n",
    "tensorize_transform = transforms.Compose([transforms.Resize((128, 128)),\n",
    "                                          transforms.ToTensor()])\n",
    "\n",
    "val_dataset = CombTrain_VQ_VAE_dataset(val_imgs_path, transform=tensorize_transform)\n",
    "\n",
    "validation_loader = DataLoader(val_dataset, batch_size=21, batch_sampler=None, drop_last=True, pin_memory=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8453a418",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.5].\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def val_(model,validation_loader):\n",
    "    model.eval()\n",
    "\n",
    "    valid_originals = next(iter(validation_loader))\n",
    "    valid_originals = valid_originals.to(device)\n",
    "\n",
    "    vq_output_eval = model._encoder(valid_originals)\n",
    "    _, valid_quantize, _, _ = model._vq_vae(vq_output_eval)\n",
    "    valid_reconstructions = model._decoder(valid_quantize)\n",
    "    return valid_originals, valid_reconstructions\n",
    "    \n",
    "org, recon_out = val_(model, validation_loader)\n",
    "show(make_grid((org+0.5).cpu().data), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "239b2606",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.2288179].\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(make_grid((recon_out+0.5).cpu().data), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a5e55be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model,'weight/VQ-VAE_chn_.pth')    #保存所有的网络参数\n",
    "torch.save(model.state_dict(),'weight/VQ-VAE_Parms_chn_.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ec4963c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_dim, num_embeddings, commitment_cost, decay = 256, 100, 0.25, 0\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Model(num_embeddings, embedding_dim, commitment_cost, decay).to(device)\n",
    "models = torch.load('weight/VQ-VAE_chn_.pth')\n",
    "encoder = models._encoder\n",
    "encoder.requires_gradq = False\n",
    "encoder.to(\"cpu\")\n",
    "#定义dataset\n",
    "class CombTrain_VQ_VAE_dataset(Dataset):\n",
    "    def __init__(self, root, transform = None):\n",
    "        self.img_path = root\n",
    "        self.transform = transform\n",
    "        self.imgs = self.read_file(self.img_path)\n",
    "        # img = Image.open(self.imgs[0])\n",
    "        # img = self.transform(img)\n",
    "        # print(img.shape)\n",
    "\n",
    "\n",
    "    def read_file(self, path):\n",
    "        \"\"\"从文件夹中读取数据\"\"\"\n",
    "        files_list = os.listdir(path)\n",
    "        file_path_list = [os.path.join(path, img) for img in files_list]\n",
    "        file_path_list.sort()\n",
    "        return file_path_list\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name = self.imgs[index]\n",
    "        img = Image.open(img_name)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img) #Tensor [C H W] [1 128 128]\n",
    "        ret =(img_name, \n",
    "              img\n",
    "        )\n",
    "        return ret\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.imgs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_imgs_path = 'data/content/arial'\n",
    "tensorize_transform = transforms.Compose([transforms.Resize((128, 128)),\n",
    "                                          transforms.ToTensor()])\n",
    "\n",
    "batch = 136 # all content imgs\n",
    "\n",
    "sim_dataset = CombTrain_VQ_VAE_dataset(train_imgs_path, transform=tensorize_transform)\n",
    "\n",
    "sim_loader = DataLoader(sim_dataset, batch_size=batch, batch_sampler=None, drop_last=False, pin_memory=True)\n",
    "\n",
    "similarity = []\n",
    "\n",
    "def CosineSimilarity(tensor_1, tensor_2):\n",
    "    normalized_tensor_1 = tensor_1 / tensor_1.norm(dim=-1, keepdim=True)\n",
    "    normalized_tensor_2 = tensor_2 / tensor_2.norm(dim=-1, keepdim=True)\n",
    "    return (normalized_tensor_1 * normalized_tensor_2).sum(dim=-1)\n",
    "\n",
    "\n",
    "while True:\n",
    "    data = next(iter(sim_loader))\n",
    "    img_name = data[0]\n",
    "    img_tensor = data[1]\n",
    "    img_tensor = img_tensor - 0.5 # normalize to [-0.5, 0.5]\n",
    "    img_tensor = img_tensor.to(\"cpu\")\n",
    "    \n",
    "    #得到了conten的feature\n",
    "    content_feature = encoder(img_tensor)\n",
    "    # print(content_feature.shape)\n",
    "    vector = content_feature.view(content_feature.shape[0], -1)\n",
    "    # print(vector.shape)\n",
    "    \n",
    "    sim_all = {}\n",
    "    for i in range(0,batch):\n",
    "        char_i = hex(ord(img_name[i][-5]))[2:].upper()\n",
    "        dict_sim_i = {char_i:{}}\n",
    "        for j in range(0,batch):\n",
    "            char_j = hex(ord(img_name[j][-5]))[2:].upper()\n",
    "            similarity = CosineSimilarity(vector[i],vector[j])\n",
    "            if i==j:\n",
    "                similarity=1.0\n",
    "            sim_i2j = {char_j:float(similarity)}\n",
    "            dict_sim_i[char_i].update(sim_i2j)\n",
    "        sim_all.update(dict_sim_i)\n",
    "\n",
    "        \n",
    "    dict_json=json.dumps(sim_all)#转化为json格式文件\n",
    "\n",
    "    #将json文件保存为.json格式文件\n",
    "    with open('weight/all_char_similarity_unicode.json','w+') as file:\n",
    "        file.write(dict_json)    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9318891b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'41': 0.9999982118606567, '42': 0.7081384658813477, '43': 0.7081520557403564, '44': 0.704740047454834, '45': 0.7111393213272095, '46': 0.7403019666671753, '47': 0.6886608600616455, '48': 0.7658683657646179, '49': 0.7868775129318237, '4A': 0.7598836421966553, '4B': 0.7306910753250122, '4C': 0.7707200050354004, '4D': 0.6924388408660889, '4E': 0.7303280830383301, '4F': 0.671463131904602, '50': 0.748375415802002, '51': 0.6545066237449646, '52': 0.7566184997558594, '53': 0.7132596969604492, '54': 0.7551020979881287, '55': 0.7102736234664917, '56': 0.7442779541015625, '57': 0.8275949954986572, '58': 0.7312769293785095, '59': 0.7026399970054626, '5A': 0.7219407558441162, '61': 0.7843235731124878, '62': 0.7672441005706787, '63': 0.7854885458946228, '64': 0.7559870481491089, '65': 0.7476027607917786, '66': 0.7906454801559448, '67': 0.7607115507125854, '68': 0.7875646948814392, '69': 0.7761615514755249, '6A': 0.765097439289093, '6B': 0.7409729361534119, '6C': 0.7897593379020691, '6D': 0.6550687551498413, '6E': 0.8301247954368591, '6F': 0.7619242668151855, '70': 0.7920520305633545, '71': 0.7736482620239258, '72': 0.7870773077011108, '73': 0.7775485515594482, '74': 0.7825912237167358, '75': 0.7584034204483032, '76': 0.7763718366622925, '77': 0.7522865533828735, '78': 0.7313387989997864, '79': 0.726921796798706, '7A': 0.725687563419342, '401': 0.7425539493560791, '406': 0.7868775129318237, '410': 1.0, '411': 0.7141074538230896, '412': 0.7081384658813477, '413': 0.7891838550567627, '414': 0.671262264251709, '415': 0.7111393213272095, '416': 0.6908732652664185, '417': 0.7097258567810059, '418': 0.7335659861564636, '419': 0.7329230308532715, '41A': 0.7321587800979614, '41B': 0.7939010858535767, '41C': 0.6924388408660889, '41D': 0.7658683657646179, '41E': 0.671463131904602, '41F': 0.7741749286651611, '420': 0.748375415802002, '421': 0.7081520557403564, '422': 0.7551020979881287, '423': 0.7308635115623474, '424': 0.6394842863082886, '425': 0.7312769293785095, '426': 0.7002301216125488, '427': 0.786457896232605, '428': 0.6921324729919434, '429': 0.6506130695343018, '42A': 0.6971485614776611, '42B': 0.6404670476913452, '42C': 0.7214118242263794, '42D': 0.6704051494598389, '42E': 0.6994641423225403, '42F': 0.7566848993301392, '430': 0.7843235731124878, '431': 0.764085054397583, '432': 0.776310920715332, '433': 0.7951553463935852, '434': 0.8553245067596436, '435': 0.7476027607917786, '436': 0.7763044834136963, '437': 0.7863154411315918, '438': 0.7663369178771973, '439': 0.8027874231338501, '43A': 0.7547863721847534, '43B': 0.8328520059585571, '43C': 0.7543553113937378, '43D': 0.7593892812728882, '43E': 0.7619242668151855, '43F': 0.8195605874061584, '440': 0.7920520305633545, '441': 0.7854885458946228, '442': 0.744288444519043, '443': 0.726921796798706, '444': 0.6232376098632812, '445': 0.7313387989997864, '446': 0.7967040538787842, '447': 0.7818112373352051, '448': 0.6590218544006348, '449': 0.7140251398086548, '44A': 0.7302473783493042, '44B': 0.7157605886459351, '44C': 0.7609111070632935, '44D': 0.7776674628257751, '44E': 0.6902155876159668, '44F': 0.7991561889648438, '451': 0.7968271970748901, '456': 0.7761615514755249, '492': 0.7462469339370728, '493': 0.783951997756958, '49A': 0.7765004634857178, '49B': 0.7735833525657654, '4A2': 0.7631754279136658, '4A3': 0.7992008924484253, '4AE': 0.7081865668296814, '4AF': 0.7443225383758545, '4B0': 0.7498584985733032, '4B1': 0.7219023704528809, '4BA': 0.7716108560562134, '4BB': 0.7875646948814392, '4D8': 0.6495391130447388, '4D9': 0.7888869047164917, '4E8': 0.6471352577209473, '4E9': 0.751866340637207}\n"
     ]
    }
   ],
   "source": [
    "with open('weight/all_char_similarity_unicode.json','r+') as file:\n",
    "    content=file.read()\n",
    "    \n",
    "content=json.loads(content)#将json格式文件转化为python的字典文件\n",
    "print(content['410'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45eff905-eead-4783-a85c-53aa0956f4a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
